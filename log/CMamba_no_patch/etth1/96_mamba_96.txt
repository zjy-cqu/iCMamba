Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           CMamba_no_patch_ETTh1_96_96Model:              CMamba              

[1mData Loader[0m
  Data:               ETTh1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            128                 
  n heads:            8                   e layers:           3                   
  d layers:           1                   d FF:               128                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        1                   Itr:                1                   
  Train Epochs:       100                 Batch Size:         64                  
  Patience:           3                   Learning Rate:      0.0005              
  Des:                Exp                 Loss:               MAE                 
  Lradj:              type3               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_CMamba_no_patch_ETTh1_96_96_CMamba_ETTh1_ftM_sl96_ll0_pl96_dm128_std1.0_el3_rd2_df128_fc3_ebtimeF_dtTrue_bs64_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8449
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.9908029
	speed: 0.0329s/iter; left time: 430.7579s
Epoch: 1 cost time: 4.240605354309082
Epoch: 1, Steps: 132 | Train Loss: 3.1244227 Vali Loss: 0.8752054 Test Loss: 0.7945890
Validation loss decreased (inf --> 0.875205).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.8791900
	speed: 0.0590s/iter; left time: 765.3578s
Epoch: 2 cost time: 3.8802378177642822
Epoch: 2, Steps: 132 | Train Loss: 1.0044139 Vali Loss: 0.8748841 Test Loss: 0.7957690
Validation loss decreased (0.875205 --> 0.874884).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.9994631
	speed: 0.0582s/iter; left time: 746.5624s
Epoch: 3 cost time: 3.6397106647491455
Epoch: 3, Steps: 132 | Train Loss: 1.0008259 Vali Loss: 0.8749964 Test Loss: 0.7953320
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0005
	iters: 100, epoch: 4 | loss: 0.9981042
	speed: 0.0564s/iter; left time: 716.8982s
Epoch: 4 cost time: 3.7927908897399902
Epoch: 4, Steps: 132 | Train Loss: 0.9983292 Vali Loss: 0.8749684 Test Loss: 0.7954362
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00045000000000000004
	iters: 100, epoch: 5 | loss: 1.0337269
	speed: 0.0586s/iter; left time: 737.2111s
Epoch: 5 cost time: 4.0405800342559814
Epoch: 5, Steps: 132 | Train Loss: 0.9944246 Vali Loss: 0.8747536 Test Loss: 0.7962762
Validation loss decreased (0.874884 --> 0.874754).  Saving model ...
Updating learning rate to 0.00040500000000000003
	iters: 100, epoch: 6 | loss: 1.0443524
	speed: 0.0595s/iter; left time: 740.1731s
Epoch: 6 cost time: 3.9583001136779785
Epoch: 6, Steps: 132 | Train Loss: 1.0004199 Vali Loss: 0.8750868 Test Loss: 0.7949930
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0003645000000000001
	iters: 100, epoch: 7 | loss: 1.0571584
	speed: 0.0597s/iter; left time: 734.6089s
Epoch: 7 cost time: 3.871361017227173
Epoch: 7, Steps: 132 | Train Loss: 0.9980852 Vali Loss: 0.8751422 Test Loss: 0.7947969
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00032805000000000003
	iters: 100, epoch: 8 | loss: 0.9590023
	speed: 0.0575s/iter; left time: 699.6663s
Epoch: 8 cost time: 3.777494192123413
Epoch: 8, Steps: 132 | Train Loss: 1.0004233 Vali Loss: 0.8751303 Test Loss: 0.7948367
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_CMamba_no_patch_ETTh1_96_96_CMamba_ETTh1_ftM_sl96_ll0_pl96_dm128_std1.0_el3_rd2_df128_fc3_ebtimeF_dtTrue_bs64_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (2785, 96, 7) (2785, 96, 7)
test shape: (2785, 96, 7) (2785, 96, 7)
mse:1.1100434064865112, mae:0.7962755560874939
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           CMamba_no_patch_ETTh1_96_96Model:              CMamba              

[1mData Loader[0m
  Data:               ETTh1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            128                 
  n heads:            8                   e layers:           3                   
  d layers:           1                   d FF:               128                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        1                   Itr:                1                   
  Train Epochs:       100                 Batch Size:         64                  
  Patience:           3                   Learning Rate:      0.005               
  Des:                Exp                 Loss:               MAE                 
  Lradj:              type3               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_CMamba_no_patch_ETTh1_96_96_CMamba_ETTh1_ftM_sl96_ll0_pl96_dm128_std1.0_el3_rd2_df128_fc3_ebtimeF_dtTrue_bs64_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8449
val 2785
test 2785
	iters: 100, epoch: 1 | loss: nan
	speed: 0.0332s/iter; left time: 434.4548s
Epoch: 1 cost time: 4.223019599914551
Epoch: 1, Steps: 132 | Train Loss: nan Vali Loss: nan Test Loss: nan
Validation loss decreased (inf --> nan).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: nan
	speed: 0.0574s/iter; left time: 744.8766s
Epoch: 2 cost time: 3.902994394302368
Epoch: 2, Steps: 132 | Train Loss: nan Vali Loss: nan Test Loss: nan
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.005
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           CMamba_no_patch_ETTh1_96_96Model:              CMamba              

[1mData Loader[0m
  Data:               ETTh1               Root Path:          ./dataset/ETT-small/
  Data Path:          ETTh1.csv           Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            96                  Label Len:          0                   
  Pred Len:           96                  Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             7                   Dec In:             7                   
  C Out:              7                   d model:            128                 
  n heads:            8                   e layers:           3                   
  d layers:           1                   d FF:               128                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        1                   Itr:                1                   
  Train Epochs:       100                 Batch Size:         64                  
  Patience:           3                   Learning Rate:      0.001               
  Des:                Exp                 Loss:               MAE                 
  Lradj:              type3               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_CMamba_no_patch_ETTh1_96_96_CMamba_ETTh1_ftM_sl96_ll0_pl96_dm128_std1.0_el3_rd2_df128_fc3_ebtimeF_dtTrue_bs64_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8449
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.9907261
	speed: 0.0333s/iter; left time: 435.8181s
Epoch: 1 cost time: 4.289992094039917
Epoch: 1, Steps: 132 | Train Loss: 7.2620600 Vali Loss: 0.8754662 Test Loss: 0.7936701
Validation loss decreased (inf --> 0.875466).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.8792216
	speed: 0.0595s/iter; left time: 771.2910s
Epoch: 2 cost time: 3.8951380252838135
Epoch: 2, Steps: 132 | Train Loss: 1.3684340 Vali Loss: 0.8747096 Test Loss: 0.7964942
Validation loss decreased (0.875466 --> 0.874710).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 3 | loss: 0.9994972
	speed: 0.0580s/iter; left time: 745.0637s
Epoch: 3 cost time: 3.8045411109924316
Epoch: 3, Steps: 132 | Train Loss: 1.0008402 Vali Loss: 0.8749745 Test Loss: 0.7954499
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.001
	iters: 100, epoch: 4 | loss: 0.9981021
	speed: 0.0586s/iter; left time: 744.5261s
Epoch: 4 cost time: 3.9466440677642822
Epoch: 4, Steps: 132 | Train Loss: 0.9983467 Vali Loss: 0.8750171 Test Loss: 0.7952831
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0009000000000000001
